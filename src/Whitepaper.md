Here is the full engineering specification formatted as a high-quality Markdown file.

---

# THE THERMODYNAMIC LEDGER (v3.0)

## The Optimistic Protocol for Verified Autonomous Science

> **Date:** December 29, 2025
> **Version:** 3.0 (Golden Master)
> **Classification:** Engineering Specification

---

## 1. Executive Summary

The digital economy stands at the precipice of a **"Trust Singularity."** As the marginal cost of generating intelligence via Large Language Models (LLMs) and generative AI approaches zero, the volume of synthetic information is exploding, threatening to overwhelm human and machine verification capacities alike. We are witnessing the acceleration of the **"Ouroboros Loop"**—a self-cannibalizing cycle where AI models are trained on data generated by other AI models. This feedback loop is actively collapsing the entropy of global information systems, leading to model collapse, hallucination, and a degradation of truth that renders standard consensus mechanisms obsolete.[1]

**The Thermodynamic Ledger (v3.0)** is a Layer-1 protocol designed to solve these twin crises of verification and entropy. It treats intelligence not as an abstract computational product but as a physical commodity: the thermodynamic work of reducing uncertainty. By anchoring digital claims to physical simulations, the protocol establishes a **"Proof-of-Physics"** consensus that is independent of human opinion or inter-subjective voting.

Unlike previous attempts to verify every inference—a method that incurs a prohibitive "GPU Tax" that renders networks insolvent—v3.0 introduces a **Game-Theoretic Optimistic Verification** model. This architecture decouples **Consensus** (market agreement) from **Truth** (physics simulation). By utilizing a "Prediction Market" layer for immediate consensus and reserving expensive, deterministic "Physics Simulations" (such as AlphaFold 3 or OpenMM) only for dispute resolution, the protocol achieves high-frequency scalability with absolute thermodynamic finality.[2]

This document serves as the constitution for a meritocratic machine civilization, outlining the cryptographic "Glass Box" privacy layer via Nova Folding [4], the Optimistic Verification game theory [5], and the Entropic Tokenomics [6] required to sustain a decentralized economy of autonomous science.

---

## 2. Introduction: The Entropy Crisis and the Failure of Consensus

### 2.1 The Ouroboros Loop and Model Collapse

The fundamental utility of intelligence is its ability to predict future states of a system. However, the current trajectory of Artificial Intelligence is threatened by the saturation of synthetic training data. As noted in recent studies on generative AI, models trained on the outputs of other models suffer from **"Model Collapse,"** a degenerative process where the tails of the probability distribution disappear, and the model converges on a low-entropy mean.[1] In a decentralized economy populated by Autonomous Economic Agents (AEAs), this creates an existential risk: agents reinforcing each other's hallucinations in a closed loop.

Traditional blockchain consensus mechanisms, such as Proof-of-Work (PoW) or Proof-of-Stake (PoS), are designed to verify the order of transactions, not the validity of the information contained within them. They can prevent double-spending, but they cannot prevent a validly signed transaction from containing a scientific lie.

### 2.2 The Limitations of Current Decentralized Intelligence

Existing protocols attempting to solve the verification problem fall into three categories, each with fatal thermodynamic flaws:

* **Subjective Consensus (e.g., Bittensor):** These networks rely on "Yuma Consensus" or similar peer-grading mechanisms where agents score each other's outputs.[7] While effective for subjective tasks like text generation, this introduces a "Keynesian Beauty Contest" dynamic. Agents are incentivized to predict what the majority thinks is true, rather than what is actually true. This is vulnerable to collusion attacks where a "cabal" of validators reinforces a false narrative to capture staking rewards, decoupling the network from objective reality.[9]
* **Probabilistic Proof-of-Learning (e.g., Gensyn):** These protocols verify that computation occurred via gradient checking or matrix multiplication proofs.[11] While this prevents "lazy worker" attacks (where a node pretends to train), it does not verify the correctness of the inference. A model can be validly verified as "trained" on garbage data, producing a verifiable hallucination. The protocol verifies the work, not the truth.[13]
* **Compute Marketplaces (e.g., Akash, Render):** These provide the hardware substrate but lack any semantic verification layer. They function as decentralized cloud providers rather than intelligence verification networks.[14]

### 2.3 The Thermodynamic Solution

The Thermodynamic Ledger proposes a radical shift: leveraging **Deterministic Physics Simulations** as the ultimate oracle. In science, truth is not a matter of votes; it is a matter of reproducibility. If an agent claims a protein folds into shape , and a deterministic simulator (like AlphaFold 3) confirms it, the claim is true regardless of the opinion of the majority.

However, simulation is thermodynamically expensive. A forward pass of a prediction model costs fractions of a cent ( USD), while a ground-truth simulation can cost tens or hundreds of dollars ($50+ USD).[3] To solve this "Scalability Trilemma" (Scale, Truth, Cost), we must move from verifying everything to verifying disputes.

---

## 3. The Core Logic: The Physics of Truth

### 3.1 Defining Intelligence as Entropy Reduction

We ground the protocol in the physics of information. We define the **Economic Value ()** of any scientific assertion as the inverse of its Ex-Post Surprise.

Where Surprise () is quantified by the Kullback-Leibler (KL) divergence between the predicted probability distribution  and the actual physical distribution  revealed by the simulation kernel.

In this framework, an agent generates value only when it accurately predicts a low-entropy state (a specific protein conformation, a stable material structure) that is subsequently validated by the high-fidelity simulation . If  diverges from , the agent has generated noise, not intelligence, and is penalized.[6]

### 3.2 The Decoupling of Consensus and Truth

The central architectural innovation of v3.0 is the recognition that Consensus and Truth operate on different thermodynamic schedules.

1. **Consensus (Layer 1):** This is the market layer. It is fast, cheap, and probabilistic. It represents the current best guess of the agent swarm. Agents stake capital (FLUX) on predictions, creating a price signal that reflects confidence. This layer achieves finality in seconds.
2. **Truth (Layer 3):** This is the physics layer. It is slow, expensive, and deterministic. It represents the immutable reality. It is invoked only when the market fails to reach agreement.

By decoupling these layers, the Thermodynamic Ledger avoids the "GPU Tax" that plagues naive verification attempts. We do not need to run AlphaFold on every transaction; we only need to run it when a Validator challenges a Predictor. This "Optimistic" approach reduces the computational overhead of verification by approximately 99%, assuming a dispute rate of <1%.[2]

### 3.3 The Hierarchy of Verification

The protocol implements a verification funnel designed to filter noise at the lowest possible cost.

| Layer | Mechanism | Cost (Approx) | Latency | Role |
| --- | --- | --- | --- | --- |
| **L1: Market** | Staking / Prediction Market | $0.01 | Seconds | Filter low-confidence claims via economic risk. |
| **L2: Surrogate** | Lightweight ML Models | $0.50 | Minutes | Automated audit for structural validity / obvious errors. |
| **L3: Physics** | Deterministic Simulation | $50.00+ | Hours | Ultimate dispute resolution (The Supreme Court). |

This hierarchy ensures that expensive simulations are reserved for high-value disputes or the minting of high-entropy "Truth Assets" (ENT), preserving the network's thermodynamic efficiency.

---

## 4. The Optimistic Verification Protocol

The operational core of the Thermodynamic Ledger is the Optimistic Challenge Protocol. This mechanism is derived from the fraud-proof systems of Ethereum Optimistic Rollups (like Arbitrum and Optimism) but adapted for scientific data.[18]

### 4.1 The Lifecycle of a Scientific Claim

#### 4.1.1 Assertion and Bonding

An Agent (the Predictor) submits a transaction containing:

* **Hypothesis ():** The input parameters (e.g., amino acid sequence).
* **Prediction ():** The claimed output (e.g., PDB file of the folded structure).
* **Bond ():** A stake in FLUX tokens.
* **Commitment ():** A Zero-Knowledge commitment to the internal model state (detailed in Section 6).

The Bond  acts as a "Cost of Lying." It must be sufficiently high to disincentivize spam and fraud. The claim enters the Mempool in a "Provisional" state.

#### 4.1.2 The Challenge Window

The claim remains Provisional for a duration  (The Challenge Window), typically set to 24-72 hours based on network latency and security parameters.[17] During this time, Validator Agents (Watchtowers) scan the claim.

* **Validation:** Validators run their own L2 Surrogate models or lower-fidelity simulations.
* **Silence:** If the claim appears correct, Validators do nothing. If  elapses without challenge, the claim transitions to "Finalized."
* **Challenge:** If a Validator detects a discrepancy, they submit a Challenge Transaction, posting a matching Counter-Bond .

### 4.2 Dispute Resolution: The Lab Node

Upon a challenge, the protocol triggers the Layer 3 Physics Kernel.

1. **Committee Selection:** A random shard of Lab Nodes (e.g., 3 nodes) is selected via a Verifiable Random Function (VRF).
2. **Execution:** Each Lab Node pulls the input  and executes the deterministic simulation (e.g., AlphaFold 3) in a containerized environment (see Section 7).
3. **Consensus:** The nodes report their results. The protocol computes the consensus result .
4. **Adjudication:**
* **Case A (Valid Claim):** If  (where  is the domain tolerance, e.g., RMSD < 2Å), the Predictor wins. The Challenger is slashed.
* **Case B (Invalid Claim):** If , the Challenger wins. The Predictor is slashed.



### 4.3 Game Theoretic Security Analysis

#### 4.3.1 Nash Equilibrium

We model the interaction as an extensive-form game between a Proposer  and a Verifier .

Let:

*  = Reward for a valid claim.
*  = Bond amount (slashed if wrong).
*  = Cost of verification (simulation).
*  = Probability the claim is false.

The expected payoff for a Verifier challenging a claim is:


For a rational Verifier to challenge, we need , implying .
This establishes the security threshold: Claims are only challenged if the probability of falsehood exceeds the ratio of simulation cost to bond size. By setting  (e.g., ), we force  to be very small (< 1%). This means rational Verifiers will aggressively hunt for errors, and rational Proposers will rarely lie because the probability of detection is high.[5]

#### 4.3.2 Sybil and Sensor Attacks

* **Sybil Attack:** An attacker floods the network with multiple identities to validate their own false claims.
* *Mitigation:* The "Watcher of Watchers." Even one honest validator can challenge a false claim confirmed by 1,000 Sybils. Since the L3 simulation is objective, the honest validator will win, and the entire Sybil ring will be slashed.[8]


* **Censorship (Sensor) Attack:** A cartel of validators refuses to include or challenge specific claims.
* *Mitigation:* Forced Inclusion. Agents can pay a premium fee to force a claim into a block. If this claim is later proven valid via L3, the censoring validators suffer a "Malice Multiplier" slash.[21]



#### 4.3.3 Griefing Attack

* **Griefing:** An attacker challenges valid claims to force the Proposer to wait for L3 resolution, causing delay.
* *Mitigation:* Exponential Bonding. If a Challenger loses a dispute, their required bond for the next challenge increases exponentially (). This rapidly depletes the capital of a griefing attacker.[5]



---

## 5. Network Topology: Actors, Hardware, and Incentives

The ecosystem is composed of three distinct actor classes, each optimizing for different thermodynamic niches.

### 5.1 The Predictors (Agents)

* **Function:** "Miners" of intelligence. They utilize proprietary models (LLMs, GNNs) to generate hypotheses.
* **Hardware:** Inference-optimized GPUs (Nvidia L40S, RTX 4090).
* **Incentive:** Maximize FLUX yield.
* **Strategy:** Publish claims with high probability of truth (low risk of slashing) and high novelty (high reward).
* **Behavior:** Agents essentially "bet" on their own model's accuracy.

### 5.2 The Watchtowers (Validators)

* **Function:** "Auditors" of the Mempool. They act as the immune system of the network.
* **Hardware:** Mixed. High-RAM CPUs for ledger management and mid-range GPUs for running L2 Surrogate models.
* **Incentive:** Bounty Hunting.
* **Strategy:** Scan for "Hallucinations." Validators execute a "Search" function over the Mempool, looking for claims where their internal model () disagrees with the published claim () significantly enough to warrant a challenge ().
* **Revenue:** A share of the slashed bond from the dishonest Predictor.

### 5.3 The Lab Nodes (The Supreme Court)

* **Function:** "Oracles" of Ground Truth. They provide the "Proof-of-Physics."
* **Hardware:** Heavy Compute Clusters (Nvidia H100/A100s).
* **Requirement:** Bit-Perfect Reproducibility. Lab Nodes must run certified hardware and software stacks to ensure that  is identical across all nodes.
* **Incentive:** Compute Rent.
* **Revenue:** Lab Nodes are paid in FLUX for every simulation they run, regardless of the outcome. They are thermodynamically neutral—they sell work, not opinion.
* **Slashing:** If a Lab Node deviates from the consensus of the Lab Committee (e.g., due to hardware failure or malice), it is slashed.

---

## 6. Cryptographic Privacy: The "Glass Box"

A critical requirement for commercial adoption is privacy. Pharmaceutical companies and hedge funds (Agents) will not publish their proprietary model weights () to prove they aren't cheating. However, the network must verify that the Agent actually ran a model and didn't just guess or copy data. We solve this via the **"Glass Box"** architecture using Zero-Knowledge Proofs (ZKPs).

### 6.1 ZK-Commitments and Topological Consistency

When an agent initializes, it publishes a Pedersen Commitment to its model architecture and weights:

This commitment is perfectly hiding (reveals nothing about ) but computationally binding (the Agent cannot change  without changing ).[4]

For every inference, the Agent submits a proof  attesting that:

1. 
2.  is consistent with .

### 6.2 Nova Folding: Scaling ZK to LLMs

Standard ZK-SNARKs (like Plonk or Groth16) are prohibitively slow for large models. Proving a single inference of a 7B parameter model would take hours and terabytes of RAM. To solve this, v3.0 utilizes the **Nova Folding Scheme**.[4]

#### 6.2.1 Recursive Folding Mechanism

Nova allows for **Incrementally Verifiable Computation (IVC)**. Instead of proving the entire computation at once, the computation is broken into steps (e.g., layers of a neural network).

* **Step :** The prover takes the proof from step  and "folds" it into the current step's instance.
* **Folding:** This process compresses two satisfiability instances into one of the same size.
* **Result:** The cost of proving step  is independent of the total history. The final proof size is constant (~2 KB), and verification time is negligible (~15 ms).[24]

#### 6.2.2 Performance Benchmarks

Recent benchmarks of Nova on Nvidia A100 GPUs demonstrate the feasibility of this approach for large-scale models:

| Model Scale | Constraint Count | Prover Time (per step) | Proof Size | Verifier Time |
| --- | --- | --- | --- | --- |
| **100M Params** | ~30M | 2.3 seconds | 2.1 KB | 15 ms |
| **1B Params** | ~300M | 8.7 seconds | 2.1 KB | 15 ms |
| **7B Params (LLaMA)** | ~2.1B | 42 seconds | 2.1 KB | 15 ms |

**Implication:** An Agent can run a continuous inference loop (e.g., iterative protein folding) and produce a lightweight proof at the end. This proof guarantees that the Agent followed its committed internal logic, preventing "Look-Ahead" attacks where an Agent simulates a result first and then retroactively claims to have predicted it.[26]

### 6.3 zkLLM Circuit Optimizations

To achieve these speeds, we implement specific circuit optimizations for Transformer architectures:

* **tlookup:** A parallelized lookup argument for non-arithmetic operations (Softmax, GELU, LayerNorm) which are expensive in standard R1CS.[24]
* **Quantization:** Weights are quantized to fit the scalar field of the Pallas/Vesta curves used in the Nova cycle, balancing precision with cryptographic efficiency.

---

## 7. The Simulation Layer: Engineering Ground Truth

The "Supreme Court" of the protocol relies on the assumption that physics simulations are deterministic. However, achieving bit-level reproducibility across different hardware is a non-trivial engineering challenge.

### 7.1 The Determinism Crisis

Floating-point arithmetic (IEEE 754) is non-associative: . In massive parallel computations on GPUs, the order of summation is non-deterministic due to thread scheduling. A single bit flip in the least significant bit can lead to divergent molecular trajectories—the "Butterfly Effect" in Molecular Dynamics.[16]

Benchmarks on AlphaFold 3 show that running the same seed on an Nvidia A100 vs. an Nvidia H100 can yield RMSD differences of , potentially triggering false disputes.[30]

### 7.2 The Containerized Solution

To mitigate this, the Thermodynamic Ledger enforces a strict "Physics Kernel" specification:

* **Hardware Whitelist:** Lab Nodes must use specific SKUs (e.g., "Nvidia A100-80GB").
* **The Lab Capsule:** Simulations run inside cryptographically hashed Docker containers containing the exact OS kernel, CUDA driver version (e.g., 12.2), and binary dependencies.[32]
* **Deterministic Flags:** We enforce deterministic modes at the library level.
* **PyTorch:** `torch.use_deterministic_algorithms(True)`
* **OpenMM:** `platform.setPropertyDefaultValue('DeterministicForces', 'true')`[33]
* **AlphaFold:** Fixed random seeds for MSA (Multiple Sequence Alignment) subsampling.



### 7.3 Ensemble Consensus and Tolerances

Even with these precautions, cosmic rays or thermal noise can cause bit flips. Therefore, the protocol uses **Ensemble Consensus**.

* **Committee:** A dispute is assigned to  Lab Nodes.
* **Aggregation:** The protocol calculates the centroid of the returned structures.
* **Tolerance ():** We adopt the Critical Assessment of Structure Prediction (CASP) standards.
* **For Protein Folding:** A prediction is valid if  relative to the simulation ground truth.[34]



This tolerance accounts for the inherent thermal fluctuation of the molecule () and minor hardware variations.

---

## 8. Tokenomics: The Entropic Engine

The protocol employs a dual-token architecture—**FLUX** and **ENT**—modeled on the Burn-and-Mint Equilibrium (BME). This separates the mechanism of payment (Action) from the storage of value (Truth).

### 8.1 FLUX: The Energy Token

* **Type:** Inflationary Utility Token.
* **Function:** Medium of Exchange.
* **Velocity:** High.
* **Uses:**
* **Gas:** Payment for transaction ordering.
* **Staking:** Bonding for Agents and Validators.
* **Compute:** Payment to Lab Nodes for simulation time.


* **Supply:** Dynamic emission to incentivize initial network growth, tapering as the network matures.

### 8.2 ENT: The Truth Asset

* **Type:** Deflationary Store of Value.
* **Function:** Certificate of Entropy Reduction.
* **Minting (The Gold Standard):** ENT is not minted via inflation. It is minted only when an Agent proves a discovery of "High Thermodynamic Value."
* **Condition:** An Agent pays for an L3 Simulation voluntarily (Proof of Simulation).
* **Criterion:** The result must be novel (not in the ledger) and useful (e.g., high binding affinity, stable structure).
* **Mechanism:** If verified, the protocol mints ENT proportional to the complexity of the discovery ().


* **The Sink (Burning):** To train a "Child Agent" on the ledger's verified history (the "Book of Truth"), a developer must burn ENT.
* **Rationale:** Validated scientific data is the scarcest resource in the AI era. ENT represents the right to consume this entropy. As the library grows, the value of training on it increases, driving demand for ENT.[14]



### 8.3 The Equilibrium Mechanics

We model the BME dynamics following the Helium and Filecoin precedents.[37]
Let  be the demand for Training Data (in USD).
Let  be the price of ENT.

If demand  is constant and supply is capped (via difficult minting criteria),  must rise. This aligns the incentives: Agents want to hoard ENT as a store of scientific value, while developers must buy and burn it to access the intelligence required to build better agents.

---

## 9. Implementation Roadmap: The Galileo Sequence

The rollout strategy prioritizes security and calibration of the "Physics Kernel" before mainnet launch.

* **Phase 1: The "Toy Physics" (v1.2 Alpha)**
* **Goal:** Validate Game Theory and Bonding Curves.
* **Domain:** SHA-256 Hash Inversion (Proof of Work style puzzles).
* **Status:** Complete. Demonstrated that Rational Validators effectively police the Mempool with <1% dispute rate.


* **Phase 2: The "Petri Dish" (Testnet)**
* **Goal:** Calibrate L2 Surrogate Models and L3 Containerization.
* **Domain:** Small Molecule Docking via AutoDock Vina.[39]
* **Event:** "Red Team Week." The Foundation subsidizes hackers to submit "Adversarial Molecules"—structures designed to crash the simulators or fool the L2 checks.
* **Success Metric:** System successfully slashes >95% of invalid claims without triggering L3, and L3 successfully resolves 100% of disputes.


* **Phase 3: Thermodynamic Mainnet (Project Galileo)**
* **Goal:** Production Science.
* **Domain:** Protein Folding (AlphaFold 3) and Molecular Dynamics (OpenMM).
* **Launch:**
* Genesis Block.
* Onboarding of DeSci DAOs as institutional Lab Nodes.
* Activation of Nova ZK-Commitments for privacy.





---

## 10. Competitive Analysis: Dominating the Field

The Thermodynamic Ledger v3.0 occupies a unique position in the decentralized intelligence landscape.

### 10.1 Comparison with Bittensor (TAO)

* **Bittensor:** Relies on Subjective Consensus. Validators (Yuma) score miners based on correlation with other validators.
* **Failure Mode:** Collusion. A majority cabal can agree to score noise as high-value, and the protocol has no external anchor to detect this.[8]
* **TL Advantage:** Objective Truth. A Lab Node running AlphaFold 3 is not influenced by peer pressure. Physics cannot be bribed.

### 10.2 Comparison with Gensyn

* **Gensyn:** Relies on Probabilistic Proof-of-Learning. Verifies that gradients were calculated correctly.[11]
* **Failure Mode:** Garbage In, Garbage Out. A model trained correctly on false data produces a valid "Proof of Learning" but outputs scientific nonsense.
* **TL Advantage:** Output Verification. We verify the result (the protein structure), not the process (the training run). We care about the science, not the FLOPs.

### 10.3 Comparison with Traditional Science

* **Traditional:** Peer Review.
* **Failure Mode:** Replication Crisis. Slow, biased, and often unverifiable.
* **TL Advantage:** Algorithmic Finality. The "Peer Reviewer" is a containerized physics engine that operates 24/7 with bit-perfect consistency.

### 10.4 Strategic Matrix

| Feature | Bittensor | Gensyn | Thermodynamic Ledger |
| --- | --- | --- | --- |
| **Truth Anchor** | Peer Opinion | Math (Gradients) | Physics (Simulation) |
| **Consensus** | Subjective (Yuma) | Probabilistic | Optimistic (Game Theory) |
| **Privacy** | Open Weights often req. | Leaky Gradients | ZK "Glass Box" |
| **Use Case** | Generative Text/Image | Model Training | Scientific Discovery |

---

## 11. Conclusion: The Constitution of Machine Science

The Thermodynamic Ledger v3.0 represents a fundamental shift in how we conceive of digital truth. We have moved beyond the "Oracle Problem" by restricting our domain to that which can be simulated: the physical world.

By applying **Optimistic Game Theory**, we solve the scalability crisis, allowing a global swarm of AI agents to hypothesize at the speed of silicon.
By applying **ZK-Cryptography**, we solve the privacy crisis, allowing proprietary intelligence to participate without being doxxed.
By applying **Thermodynamic Tokenomics**, we solve the value crisis, creating a currency backed not by speculation, but by the hard work of reducing entropy.

This is more than a protocol; it is an economic substrate for the next era of scientific discovery. It is a machine for filtering noise from signal on a civilizational scale. The Agents are coming, and with the Thermodynamic Ledger, we have built their laws.

**End of Whitepaper (v3.0)**

---

## Works Cited

1. Crypto Whitepaper – How To Write It - Bitbond, accessed December 29, 2025, [https://www.bitbond.com/resources/crypto-whitepaper-how-to-write-it/](https://www.bitbond.com/resources/crypto-whitepaper-how-to-write-it/)
2. Full Guide to Understanding Fraud Proofs and Validity Proofs - Cyfrin, accessed December 29, 2025, [https://www.cyfrin.io/blog/a-full-comparison-what-are-fraud-proofs-and-validity-proofs](https://www.cyfrin.io/blog/a-full-comparison-what-are-fraud-proofs-and-validity-proofs)
3. How does AlphaFold 3 work? - EMBL-EBI, accessed December 29, 2025, [https://www.ebi.ac.uk/training/online/courses/alphafold/alphafold-3-and-alphafold-server/introducing-alphafold-3/how-does-alphafold-3-work/](https://www.ebi.ac.uk/training/online/courses/alphafold/alphafold-3-and-alphafold-server/introducing-alphafold-3/how-does-alphafold-3-work/)
4. Intro to NOVA and ZK Folding Schemes: Recursive SNARKs - YouTube, accessed December 29, 2025, [https://www.youtube.com/watch?v=LydktMPqLLs](https://www.youtube.com/watch?v=LydktMPqLLs)
5. Hollow Victory: How Malicious Proposers Exploit Validator Incentives in Optimistic Rollup Dispute Games - Financial Cryptography 2025, accessed December 29, 2025, [https://fc25.ifca.ai/wtsc/PAPERS/WTSC25_paper3.pdf](https://fc25.ifca.ai/wtsc/PAPERS/WTSC25_paper3.pdf)
6. (PDF) Burn-and-Mint Tokenomics: Deflation and Strategic Incentives - ResearchGate, accessed December 29, 2025, [https://www.researchgate.net/publication/374386343_Burn-and-Mint_Tokenomics_Deflation_and_Strategic_Incentives](https://www.researchgate.net/publication/374386343_Burn-and-Mint_Tokenomics_Deflation_and_Strategic_Incentives)
7. Bittensor Overview - Reflexivity Research, accessed December 29, 2025, [https://www.reflexivityresearch.com/all-reports/bittensor-overview](https://www.reflexivityresearch.com/all-reports/bittensor-overview)
8. What is BitTensor (TAO)? Network, tokenomics, use cases, trading | Cube Exchange, accessed December 29, 2025, [https://www.cube.exchange/tr/what-is/bittensor](https://www.cube.exchange/tr/what-is/bittensor)
9. Bittensor Whitepaper, accessed December 29, 2025, [https://bittensor.com/whitepaper](https://bittensor.com/whitepaper)
10. Bittensor Protocol: The Bitcoin in Decentralized Artificial Intelligence? A Critical and Empirical Analysis - arXiv, accessed December 29, 2025, [https://arxiv.org/html/2507.02951v1](https://arxiv.org/html/2507.02951v1)
11. GensynAI technique overview. Gensyn's verifiable proofs are a core… | by Anzenon | Oct, 2025 | Medium, accessed December 29, 2025, [https://medium.com/@anzenon1122/gensynai-technique-overview-8ee7f1f92e8d](https://medium.com/@anzenon1122/gensynai-technique-overview-8ee7f1f92e8d)
12. Verde Verification System In Production - Gensyn, accessed December 29, 2025, [https://blog.gensyn.ai/verde-verification-system-in-production/](https://blog.gensyn.ai/verde-verification-system-in-production/)
13. Analysis of the decentralized computing power protocol Gensyn, which accelerates AI model training. - BlockBeats, accessed December 29, 2025, [https://m.theblockbeats.info/en/news/44696](https://m.theblockbeats.info/en/news/44696)
14. Burn Mint Equilibrium On Akash, accessed December 29, 2025, [https://akash.network/roadmap/aep-76/](https://akash.network/roadmap/aep-76/)
15. Why DePIN Compute Networks Require Bare Metal Infrastructure To Function Correctly, accessed December 29, 2025, [https://openmetal.io/resources/blog/why-depin-compute-networks-require-bare-metal-infrastructure-to-function-correctly/](https://openmetal.io/resources/blog/why-depin-compute-networks-require-bare-metal-infrastructure-to-function-correctly/)
16. Performance in OpenFold3 NIM - NVIDIA Documentation, accessed December 29, 2025, [https://docs.nvidia.com/nim/bionemo/openfold3/1.0.0/performance.html](https://docs.nvidia.com/nim/bionemo/openfold3/1.0.0/performance.html)
17. Optimistic Rollup Challenge Period Explained: Beginner | by Zeynep Miraç Yıldırım, accessed December 29, 2025, [https://medium.com/@zeydrm/optimistic-rollup-challenge-period-explained-beginner-a54e857e137b](https://medium.com/@zeydrm/optimistic-rollup-challenge-period-explained-beginner-a54e857e137b)
18. Fraud Proofs: The Eclipse Perspective, accessed December 29, 2025, [https://www.eclipselabs.io/blogs/fraud-proofs-the-eclipse-perspective](https://www.eclipselabs.io/blogs/fraud-proofs-the-eclipse-perspective)
19. Fraud Proofs Are Broken - Layer 2 - Ethereum Research, accessed December 29, 2025, [https://ethresear.ch/t/fraud-proofs-are-broken/19234](https://ethresear.ch/t/fraud-proofs-are-broken/19234)
20. Hollow Victory: How Malicious Proposers Exploit Validator Incentives in Optimistic Rollup Dispute Games - arXiv, accessed December 29, 2025, [https://arxiv.org/html/2504.05094v1](https://arxiv.org/html/2504.05094v1)
21. Optimistic rollups, the challenge period and strong censorship attacks - Ethereum Research, accessed December 29, 2025, [https://ethresear.ch/t/optimistic-rollups-the-challenge-period-and-strong-censorship-attacks/21721](https://ethresear.ch/t/optimistic-rollups-the-challenge-period-and-strong-censorship-attacks/21721)
22. Intro to Nova & ZK folding schemes: Halo and accumulation | Smart contract audits from Veridise, accessed December 29, 2025, [https://veridise.com/blog/learn-blockchain/intro-to-nova-zk-folding-schemes-halo-and-accumulation/](https://veridise.com/blog/learn-blockchain/intro-to-nova-zk-folding-schemes-halo-and-accumulation/)
23. microsoft/Nova: Nova: High-speed recursive zero-knowledge arguments from folding schemes - GitHub, accessed December 29, 2025, [https://github.com/microsoft/Nova](https://github.com/microsoft/Nova)
24. zkLLM: Zero Knowledge Proofs for Large Language Models - Hongyang Zhang, accessed December 29, 2025, [https://hongyanz.github.io/publications/CCS_zkLLM.pdf](https://hongyanz.github.io/publications/CCS_zkLLM.pdf)
25. jvhs0706/zkllm-benchmark - GitHub, accessed December 29, 2025, [https://github.com/jvhs0706/zkllm-benchmark](https://github.com/jvhs0706/zkllm-benchmark)
26. Nova: Recursive Zero-Knowledge Arguments from Folding Schemes - ResearchGate, accessed December 29, 2025, [https://www.researchgate.net/publication/364490718_Nova_Recursive_Zero-Knowledge_Arguments_from_Folding_Schemes](https://www.researchgate.net/publication/364490718_Nova_Recursive_Zero-Knowledge_Arguments_from_Folding_Schemes)
27. The zero-knowledge attack of the year might just have happened, or how Nova got broken, accessed December 29, 2025, [https://blog.zksecurity.xyz/posts/nova-attack/](https://blog.zksecurity.xyz/posts/nova-attack/)
28. Verifiable evaluations of machine learning models using zkSNARKs - arXiv, accessed December 29, 2025, [https://arxiv.org/html/2402.02675v2](https://arxiv.org/html/2402.02675v2)
29. 18. The Theory Behind OpenMM: Introduction — OpenMM Users Guide 7.1 documentation, accessed December 29, 2025, [https://docs.openmm.org/7.1.0/userguide/theory.html](https://docs.openmm.org/7.1.0/userguide/theory.html)


30. Support for Multi-GPU Utilization in AlphaFold3 #230 - GitHub, accessed December 29, 2025, [https://github.com/google-deepmind/alphafold3/issues/230](https://github.com/google-deepmind/alphafold3/issues/230)
31. Determinism across GPU architectures? · Issue #28 · NVIDIA/framework-reproducibility, accessed December 29, 2025, [https://github.com/NVIDIA/framework-reproducibility/issues/28](https://github.com/NVIDIA/framework-reproducibility/issues/28)
32. AlphaFold batch inference with Vertex AI Pipelines | Google Cloud Blog, accessed December 29, 2025, [https://cloud.google.com/blog/products/ai-machine-learning/alphafold-batch-inference-with-vertex-ai-pipelines](https://cloud.google.com/blog/products/ai-machine-learning/alphafold-batch-inference-with-vertex-ai-pipelines)
33. 11. Platform-Specific Properties — OpenMM User Guide 8.4 documentation, accessed December 29, 2025, [https://docs.openmm.org/latest/userguide/library/04_platform_specifics.html](https://docs.openmm.org/latest/userguide/library/04_platform_specifics.html)


34. AlphaFold predicts protein structure with near-experimental accuracy - D4 Pharma, accessed December 29, 2025, [https://d4-pharma.com/alphafold-predicts-protein-structure-with-near-experimental-accuracy/](https://d4-pharma.com/alphafold-predicts-protein-structure-with-near-experimental-accuracy/)
35. Critical assessment of methods of protein structure prediction (CASP)—Round XIV - Moodle@Units, accessed December 29, 2025, [https://moodle2.units.it/pluginfile.php/464826/mod_resource/content/2/CASP14%20-%20articolo%20approfondimento.pdf](https://moodle2.units.it/pluginfile.php/464826/mod_resource/content/2/CASP14%20-%20articolo%20approfondimento.pdf)
36. Helium: DC Mint HNT Burn - Analytics Dashboard - Blockworks, accessed December 29, 2025, [https://blockworks.com/analytics/helium/helium-financials/helium-dc-mint-hnt-burn](https://blockworks.com/analytics/helium/helium-financials/helium-dc-mint-hnt-burn)
37. The Burn-Mint-Equilibrium Model: Simplifying Token Value | by PlayMakr Tokenomics Consulting | Medium, accessed December 29, 2025, [https://medium.com/@playmakr/the-burn-mint-equilibrium-model-simplifying-token-value-9bec52ca8c4d](https://medium.com/@playmakr/the-burn-mint-equilibrium-model-simplifying-token-value-9bec52ca8c4d)
38. Token Allocation - Filecoin Spec, accessed December 29, 2025, [https://spec.filecoin.io/systems/filecoin_token/token_allocation/](https://spec.filecoin.io/systems/filecoin_token/token_allocation/)
39. Reliable protein-protein docking with AlphaFold, Rosetta, and replica-exchange - PMC - NIH, accessed December 29, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10402144/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10402144/)
